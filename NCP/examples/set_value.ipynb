{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from NCP.utils import FastTensorDataLoader\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from NCP.model import NCPOperator, NCPModule\n",
    "from NCP.nn.layers import MLP, ConvMLP\n",
    "from NCP.nn.losses import CMELoss\n",
    "from NCP.metrics import hellinger, kullback_leibler, wasserstein1\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_save_checkpoint(self, trainer, pl_module, checkpoint):\n",
    "        X, Y = trainer.model.batch\n",
    "        trainer.model.model._compute_data_statistics(X, Y)\n",
    "\n",
    "def restore_buffers_shape(model, state_dict):\n",
    "    model._sing_val = torch.zeros_like(state_dict['model._sing_val']).to('cpu')\n",
    "    model._sing_vec_l = torch.zeros_like(state_dict['model._sing_vec_l']).to('cpu')\n",
    "    model._sing_vec_r = torch.zeros_like(state_dict['model._sing_vec_r']).to('cpu')\n",
    "\n",
    "from NCP.examples.tools.plot_utils import setup_plots\n",
    "setup_plots()\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.ConvertImageDtype(torch.float32),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "def tofl32(x):\n",
    "    return torch.Tensor([x]).type(torch.float32)\n",
    "target_transform = transforms.Compose([transforms.Lambda(tofl32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainset = MNIST(root='./data', train=True,\n",
    "                download=True, transform=transform, target_transform=target_transform)\n",
    "trainloader = FastTensorDataLoader(trainset.data.type(torch.float32)[:, None, :, :], \n",
    "                                   trainset.targets.type(torch.float32)[:, None], \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "testset = MNIST(root='./data', train=False,\n",
    "                download=True, transform=transform, target_transform=target_transform)\n",
    "\n",
    "n_test = trainset.data.size()[0]\n",
    "X_val, X_test = torch.split(trainset.data.type(torch.float32)[:, None, :, :], n_test//2)\n",
    "Y_val, Y_test = torch.split(trainset.targets.type(torch.float32)[:, None], n_test//2)\n",
    "\n",
    "valloader = FastTensorDataLoader(X_val, Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "print(data[0].size())\n",
    "print(data[1].size())\n",
    "input_shape = data[0].size()[-1]\n",
    "label_shape = data[1].size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\Gregoire\\anaconda3\\envs\\koopman\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669: 100%|██████████| 938/938 [00:13<00:00, 67.34it/s, v_num=212, val_loss=-3.74, train_loss=-3.75]"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "gamma = 1e-2\n",
    "epochs = int(1e5)\n",
    "output_shape = 100\n",
    "\n",
    "MLP_kwargs_U = {\n",
    "    'rgb': False,&\n",
    "    'output_shape': output_shape,\n",
    "    'n_hidden': 4,\n",
    "    'layer_size': 128,\n",
    "    'dropout': 0,\n",
    "    'iterative_whitening': False\n",
    "}\n",
    "\n",
    "MLP_kwargs_V = {\n",
    "    'input_shape': label_shape,\n",
    "    'output_shape': output_shape,\n",
    "    'n_hidden': 5,\n",
    "    'layer_size': [8, 16, 32, 64, 128],\n",
    "    'dropout': 0,\n",
    "    'iterative_whitening': False\n",
    "}\n",
    "\n",
    "optimizer = Adam\n",
    "optimizer_kwargs = {\n",
    "    'lr': lr\n",
    "    }\n",
    "\n",
    "loss_fn = CMELoss\n",
    "loss_kwargs = {\n",
    "    'mode': 'split',\n",
    "    'gamma': gamma\n",
    "}\n",
    "\n",
    "reg = NCPOperator(U_operator=ConvMLP, V_operator=MLP, U_operator_kwargs=MLP_kwargs_U, V_operator_kwargs=MLP_kwargs_V)\n",
    "\n",
    "NCP_module = NCPModule(\n",
    "    reg,\n",
    "    optimizer,\n",
    "    optimizer_kwargs,\n",
    "    CMELoss,\n",
    "    loss_kwargs\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=1000, mode=\"min\")\n",
    "checkpoint_callback = CustomModelCheckpoint(save_top_k=1, monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "trainer = L.Trainer(**{\n",
    "    'accelerator': device,\n",
    "    'max_epochs': epochs,\n",
    "    'log_every_n_steps': 1,\n",
    "    'enable_progress_bar': True,\n",
    "    'devices': 1,\n",
    "    'enable_checkpointing': True,\n",
    "    'num_sanity_val_steps': 0,\n",
    "    'enable_model_summary': False,\n",
    "    }, callbacks=[early_stop, checkpoint_callback])\n",
    "\n",
    "trainer.fit(NCP_module, train_dataloaders=trainloader, val_dataloaders=valloader)\n",
    "\n",
    "# recover best model during training\n",
    "best_model_dict = torch.load(checkpoint_callback.best_model_path)\n",
    "restore_buffers_shape(reg, best_model_dict['state_dict'])\n",
    "NCP_module.load_state_dict(best_model_dict['state_dict'])\n",
    "best_model = NCP_module.model\n",
    "\n",
    "plt.figure(figsize=(17, 8))\n",
    "plt.plot(range(len(NCP_module.train_loss)), np.array(NCP_module.train_loss))\n",
    "plt.plot(range(len(NCP_module.val_loss)), np.array(NCP_module.val_loss), alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba(model, sample, classes, Y_sampling, postprocess='whitening'):\n",
    "    condprobas = np.zeros(len(classes))\n",
    "    for i, c in classes:\n",
    "        # observable is a vector to scalar function\n",
    "        fY = torch.stack([int(y_i == c) for y_i in torch.unbind(Y_sampling, dim=-1)], dim=-1).flatten() # Pytorch equivalent of numpy.apply_along_axis\n",
    "        proba = torch.sum(fY, -1) / fY.shape[0]  # vector of [k/n], k \\in [n]\n",
    "\n",
    "        Ux, sigma, Vy = model.postprocess_UV(sample, Y_sampling, postprocess)\n",
    "        Ux = Ux.flatten()\n",
    "\n",
    "        # estimating the cdf of the function f on X_t\n",
    "        Ify = torch.outer(fY, torch.ones(Vy.shape[1]))  # indicator function of fY < fY[i], put into shape (n_sample, latent_dim)\n",
    "        EVyFy = torch.mean(Vy * Ify, axis=0)  # for all latent dim, compute E (Vy * fY)\n",
    "        condprobas[i] = proba[i] + torch.sum(sigma * Ux * EVyFy)\n",
    "\n",
    "    return condprobas\n",
    "\n",
    "def is_in_interval(condprobas, classes, true_label, alpha):\n",
    "    sorted_probas = np.argsort(condprobas)\n",
    "    coverages = np.cumsum(condprobas[sorted_probas])\n",
    "    classes_in_coverage = classes[sorted_probas][coverages > alpha]\n",
    "    return true_label in classes_in_coverage\n",
    "\n",
    "#for all values in test set,\n",
    "\n",
    "# compute probas for all classes\n",
    "\n",
    "# measure coverage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_discr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m221\u001b[39m) \u001b[38;5;66;03m# contains the true values of the classes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fys, pdf_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpdf(X_test[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28;01mNone\u001b[39;00m,:,:,:], torch\u001b[38;5;241m.\u001b[39mTensor(Y_discr)[:,\u001b[38;5;28;01mNone\u001b[39;00m], postprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue target:\u001b[39m\u001b[38;5;124m'\u001b[39m, Y_test[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Y_discr = np.linspace(-1, 10, 221) # contains the true values of the classes\n",
    "\n",
    "fys, pdf_pred = best_model.pdf(X_test[0][None,:,:,:], torch.Tensor(Y_discr)[:,None], postprocess='centering')\n",
    "\n",
    "print('True target:', Y_test[0])\n",
    "plt.plot(fys, np.maximum(pdf_pred, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_discr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m221\u001b[39m) \u001b[38;5;66;03m# contains the true values of the classes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fys, pdf_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpdf(X_test[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28;01mNone\u001b[39;00m,:,:,:], torch\u001b[38;5;241m.\u001b[39mTensor(Y_discr)[:,\u001b[38;5;28;01mNone\u001b[39;00m], postprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue target:\u001b[39m\u001b[38;5;124m'\u001b[39m, Y_test[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Y_discr = np.linspace(-1, 10, 221) # contains the true values of the classes\n",
    "\n",
    "fys, pdf_pred = best_model.pdf(X_test[1][None,:,:,:], torch.Tensor(Y_discr)[:,None], postprocess='centering')\n",
    "\n",
    "print('True target:', Y_test[1])\n",
    "plt.plot(fys, np.maximum(pdf_pred, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_discr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m221\u001b[39m) \u001b[38;5;66;03m# contains the true values of the classes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fys, pdf_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpdf(X_test[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;28;01mNone\u001b[39;00m,:,:,:], torch\u001b[38;5;241m.\u001b[39mTensor(Y_discr)[:,\u001b[38;5;28;01mNone\u001b[39;00m], postprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue target:\u001b[39m\u001b[38;5;124m'\u001b[39m, Y_test[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Y_discr = np.linspace(-1, 10, 221) # contains the true values of the classes\n",
    "\n",
    "fys, pdf_pred = best_model.pdf(X_test[2][None,:,:,:], torch.Tensor(Y_discr)[:,None], postprocess='centering')\n",
    "\n",
    "print('True target:', Y_test[2])\n",
    "plt.plot(fys, np.maximum(pdf_pred, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:07<00:00, 22624532.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "gamma = 1e-2\n",
    "epochs = int(1e4)\n",
    "output_shape = 100\n",
    "\n",
    "MLP_kwargs_U = {\n",
    "    'rgb': False,\n",
    "    'output_shape': output_shape,\n",
    "    'n_hidden': 3,\n",
    "    'layer_size': 128,\n",
    "    'dropout': 0,\n",
    "    'iterative_whitening': False\n",
    "}\n",
    "\n",
    "MLP_kwargs_V = {\n",
    "    'input_shape': input_shape,\n",
    "    'output_shape': output_shape,\n",
    "    'n_hidden': 2,\n",
    "    'layer_size': 128,\n",
    "    'dropout': 0,\n",
    "    'iterative_whitening': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam\n",
    "optimizer_kwargs = {\n",
    "    'lr': lr\n",
    "    }\n",
    "\n",
    "loss_fn = CMELoss\n",
    "loss_kwargs = {\n",
    "    'mode': 'split',\n",
    "    'gamma': gamma\n",
    "}\n",
    "\n",
    "reg = NCPOperator(U_operator=ConvMLP, V_operator=MLP, U_operator_kwargs=MLP_kwargs_U, V_operator_kwargs=MLP_kwargs_V)\n",
    "\n",
    "NCP_module = NCPModule(\n",
    "    reg,\n",
    "    optimizer,\n",
    "    optimizer_kwargs,\n",
    "    CMELoss,\n",
    "    loss_kwargs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
